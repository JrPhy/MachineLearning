我們已知知道如何找到一條線來分出有些錯誤的二元資料，那麼要如何完美的分出非線性可分的資料呢?一個方法是將原有的資料轉換到另一個空間，舉例來說，我們可以將資料轉到一個橢圓方程式上，那麼轉過去的資料就是線性可分的。故步驟如下
1. 選擇一個函數 f 將原本的資料從 R<sup>m</sup> 到 R<sup>n</sup>
2. 找出在新空間中可將資料線性分離的直線
3. 再將新的資料反轉回原本的空間

## 1. 轉換式的選擇
對於一個任意資料集 $$\ D(x_{1}, x_{2}, ..., x_{m}) $$，可以將其轉為一個多項式 

$$\ f(x_{1}, x_{2}, ..., x_{m}) = \sum_{i=1}^{m}(x_{1} + x_{2} + ...+ x_{m})^i $$

當我們對此多項式展開，來看看其複雜度為多少，假設 m = 2
Q = 0, # = 1\
Q = 1, # = 1+2\
Q = 2, # = 1+2+3\
...\
Q = n, # = 1+2+3+...+(n+1) = (n+1)(n+2)/2\
可以知道其複雜度相當的高，所以實際在做轉換時不會選次數太高的多項式。且誤差並不會隨著次數增加而減少，雖然在訓練資料集中選擇高次數能降低誤差，但是實際資料的誤差可能會增加，此即為[(over-fitting)過擬合現象](https://zh.wikipedia.org/zh-tw/%E9%81%8E%E9%81%A9)

而有以下方式可以避免過擬合
1. 從次數較低的多項式開始
2. 資料清理，消除雜訊
3. [正則化](https://github.com/JrPhy/MachineLearning/blob/master/Support_Vector_Machine/Regularization.md)
4. 驗證
