前面講了許多理論，以及要如何得到 K, Q, V 矩陣，幸好現在網路發達，也有許多人願意共享自己的成果。[Hugging Face](https://huggingface.co/learn/nlp-course/zh-TW/chapter1/1?fw=pt)是目前比較有名的開源網站，不論是現在流行的預訓練集，還是目前較多人使用的 Transformer 模型，在上面都可以找到詳細的資料。最主要的就是 Encoder 和 Decoder，Transformer 就是將所有的步驟直接串起來，下圖左邊就是 Encoder，用於做閱讀理解，根據特定的標籤對文章輸入進行分類。右邊是 Decoder，根據輸入的提示生成文章。整個串起來一起用就稱為 Seq2Seq，用來生成文章的摘要或翻譯\
![img](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers-dark.svg)\
